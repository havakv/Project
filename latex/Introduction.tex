%
This project is an intro level study of statistical classification. The goal is get an overview of methods used in classification and further use this knowledge in a master's thesis. The report will start by introducing the concepts of classification through some historically well known linear classifiers. However, they will only be discussed briefly. The main focus will be on tree-based methods, and hereunder CART, Boosting mehods, Bagging and Random Forests. 
\\
\\
In statistics and machine learning, classification is the problem of finding to which category, out of a set of categories, a new observation belongs. This is done by creating a classifier on a training set of observed data, $\{\mathbf{x}_i, y_i\}_{i = 1}^N$, where $\mathbf{x}_i$ is a vector of features (covariates, predictors, etc.), and $y_i$ is the class label of the observation. 

These sort of problems arise in applications like picture and speech recognition, computer vision, document classification and medical imaging.
Over time, a variety of approaches have been suggested. Some might give a highly interpretable method, while others have more accurate predictions. Their performance might differ in different applications as well. There is still not a single method capable of outperforming all other, so knowledge about a variety of algorithms is highly beneficial. 
\\
\\
In this report it is assumed that the cost of misclassifying a point is $1$ for all points. The cost of correct classification is $0$. This is often referred to as $0/1$ classification, or the $0/1$ loss function, 
\begin{align}
  L(y, \hat y) = I\left\{ \hat y \neq y \right\}.
\end{align}
Here $\hat y$ is the prediction given by the classifier. 

The alternative would be to assign weights to different misclassifications. For example, a lending institution might consider it five times worse that a customer defaults, than not giving a loan to a customer that is able meet all payments. Often it is not hard to generalize algorithms to meet such requirements. Nevertheless,  it is considered outside the scope of this report.

It is also assumed the classes are unordered. That means the response has no ordering, like colors or pictures. Some examples of ordered classes are tax rates and feelings (bad, fine, great). Ordered classes require special techniques and will therefore not be considered here. 



\section{Notation}
\label{sec:Notation}
I have tried to follow most conventions when it comes to notation, and be consistent throughout the report. Stochastic variables have no particular notation, but is should usually follow from the context. Note the following:\\
$\mathbf{x}$ is a vector. \\
$x_i$ is an element in $\mathbf{x}$. \\
$\mathbf{x}_i$ is a predictor/data point.  \\
$\mathbf{A}$ is a matrix \\
$I\{a = b\}$ is the indicator function.\\
Subscripts on probabilities and expectations are used to either emphasize the stochastic variables, or as a substitute for conditioning. 
E.g. $P_{\mathbf{x}, y}(T(\theta, \mathbf{x}) = y) = P(T(\theta, \mathbf{x}) = y \mid \theta)$.

