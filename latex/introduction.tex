\section{Introduction}
\label{sec:Introduction}
\todo{Past tense?}
This project is an introduction to classification in statistics. The goal was get an overview of methods used in classification and further use this knowledge in a master thesis. \\
\\
The idea in classification is to find to which of a set of categories a new observation belongs. This is done by creating a classifier on a training set of observed data $(\mathbf{x}_i, y_i)$, for $i = 1, \ldots, N$, where $\mathbf{x}_i$ is a vector of features, and $y_i$ is to which class it belongs. Over time, there are a variety of approaches, no one methods that can claim the title of the best. This is because different assumptions fits different datasets, and the size of the training data is also important to consider. \\
\colorbox{yellow}{Write something about how bad methods with larger training sets do better than good algorithms with smaller sets}\\
\colorbox{yellow}{Should do some simulations on this.}\\
\colorbox{yellow}{Say something about unordered classes.}


\subsection{Notation}
\label{sub:Notation}
MCE is misclassification error. \\
SD is standard deviation. \\
$\mathbf{x}$ is a vector. \\
$x_i$ is an element in $\mathbf{x}$. \\
$\mathbf{x}_i$ is a predictor/data point.  \\
$\mathbf{x}_{ij}$ is element $j$ in $\mathbf{x}_i$. \\
$\mathbf{A}$ is a matrix \\
$I\{a = b\}$ is the indicator function.\\
Subscripts on probabilities and expectations are used to either emphasize the stochastic variables, or instead of conditioning. 
E.g. $P_{\mathbf{x}, y}(T(\theta, \mathbf{x}) = y) = P(T(\theta, \mathbf{x}) = y \mid \theta)$.

