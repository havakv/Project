% This file was created with JabRef 2.10b2.
% Encoding: UTF-8


@Article{adabag,
  Title                    = {{adabag}: An {R} Package for Classification with Boosting and Bagging},
  Author                   = {Esteban Alfaro and Mat\'ias G\'amez and Noelia Garc\'ia},
  Journal                  = {Journal of Statistical Software},
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {1--35},
  Volume                   = {54},

  Url                      = {http://www.jstatsoft.org/v54/i02/}
}

@Book{bishop,
  Title                    = {Pattern recognition and machine learning},
  Author                   = {Bishop, Christopher M and others},
  Publisher                = {springer New York},
  Year                     = {2006},
  Number                   = {4},
  Volume                   = {4}
}

@Book{breiman,
  Title                    = {Classification and Regression Trees},
  Author                   = {Breiman, Leo and Friedman, Jerome and Olshen, Richard and Stone, Charles},
  Publisher                = {Wadsworth International Group},
  Year                     = {1984}
}

@Article{copas1983,
  Title                    = {Regression, Prediction and Shrinkage},
  Author                   = {Copas, J. B.},
  Journal                  = {Journal of the Royal Statistical Society. Series B (Methodological)},
  Year                     = {1983},
  Number                   = {3},
  Pages                    = {pp. 311-354},
  Volume                   = {45},

  Abstract                 = {The fit of a regression predictor to new data is nearly always worse than its fit to the original data. Anticipating this shrinkage leads to Stein-type predictors which, under certain assumptions, give a uniformly lower prediction mean squared error than least squares. Shrinkage can be particularly marked when stepwise fitting is used: the shrinkage is then closer to that expected of the full regression rather than of the subset regression actually fitted. Preshrunk predictors for selected subsets are proposed and tested on a number of practical examples. Both multiple and binary (logistic) regression models are considered.},
  Copyright                = {Copyright © 1983 Royal Statistical Society},
  ISSN                     = {00359246},
  Jstor_articletype        = {research-article},
  Jstor_formatteddate      = {1983},
  Language                 = {English},
  Publisher                = {Wiley for the Royal Statistical Society},
  Url                      = {http://www.jstor.org/stable/2345402}
}

@Article{adaboostM1,
  Title                    = {A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting},
  Author                   = {Freund, Yoav and Schapire, Robert E},
  Journal                  = {Journal of Computer and System Sciences},
  Year                     = {1997},

  Month                    = {Aug},
  Number                   = {1},
  Pages                    = {119–139},
  Volume                   = {55},

  __markedentry            = {[havakv:]},
  Doi                      = {10.1006/jcss.1997.1504},
  ISSN                     = {0022-0000},
  Owner                    = {havakv},
  Publisher                = {Elsevier BV},
  Timestamp                = {2015.04.10},
  Url                      = {http://dx.doi.org/10.1006/jcss.1997.1504}
}

@Article{friedman,
  Title                    = {Greedy function approximation: A gradient boosting machine},
  Author                   = {Friedman, Jerome H.},
  Journal                  = {Ann. Statist.},
  Year                     = {2001},

  Month                    = {Oct},
  Number                   = {5},
  Pages                    = {1189–1232},
  Volume                   = {29},

  __markedentry            = {[havakv:6]},
  Doi                      = {10.1214/aos/1013203451},
  ISSN                     = {0090-5364},
  Owner                    = {havakv},
  Publisher                = {Institute of Mathematical Statistics},
  Timestamp                = {2015.04.14},
  Url                      = {http://dx.doi.org/10.1214/aos/1013203451}
}

@Book{modstat,
  Title                    = {The elements of statistical learning},
  Author                   = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  Publisher                = {Springer},
  Year                     = {2009},
  Number                   = {1},
  Volume                   = {2}
}

@Manual{stats,
  Title                    = {R: A Language and Environment for Statistical Computing},

  Address                  = {Vienna, Austria},
  Author                   = {{R Core Team}},
  Organization             = {R Foundation for Statistical Computing},
  Year                     = {2014},

  Url                      = {http://www.R-project.org/}
}

@Manual{rpart,
  Title                    = {rpart: Recursive Partitioning and Regression Trees},
  Author                   = {Terry Therneau and Beth Atkinson and Brian Ripley},
  Note                     = {R package version 4.1-8},
  Year                     = {2014},

  Url                      = {http://CRAN.R-project.org/package=rpart}
}

@Book{mass,
  Title                    = {Modern Applied Statistics with S},
  Author                   = {W. N. Venables and B. D. Ripley},
  Publisher                = {Springer},
  Year                     = {2002},

  Address                  = {New York},
  Edition                  = {Fourth},
  Note                     = {ISBN 0-387-95457-0},

  Url                      = {http://www.stats.ox.ac.uk/pub/MASS4}
}

